---
format: 
  revealjs:
    css: ./styles.css
    slide-number: true
    show-slide-number: all
    preview-links: auto
    embed-resources: true
    standalone: true
    progress: true
    history: true
    hash-type: number
    theme: default
    code-block-background: true
    highlight-style: zenburn
    code-link: false
    code-copy: true
    pagetitle: "Machine Learning in R with tidymodels"
    author-meta: "Jeffrey Girard"
    date-meta: "2022-10-26"
---

::: {.my-title}
# [Machine Learning]{.blue} <br />in R with tidymodels

::: {.light-silver}
[Jeffrey M. Girard | University of Kansas]{}<br />
[Technology in Psychiatry Summit 2022]{.i}
:::

![](./img/predictive_analytics_357EDD.svg){.absolute bottom=0 right=0 width=400}
:::

<!-- Overview -->

# Overview

## Instructor {.smaller}

::: {.columns .pv4}
::: {.column width="30%"}
::: {.tc}
![](./img/Girard_500x500.jpg){.br-100}

**Jeffrey Girard**, PhD<br /> [www.jmgirard.com](https://www.jmgirard.com)<br /> [jmgirard\@ku.edu](mailto:jmgirard@ku.edu)
:::
:::

::: {.column width="10%"}
:::

::: {.column width="60%"}
::: {.fragment}
#### Background

-   [Assistant Professor]{.b .green}, *University of Kansas*
-   Research Postdoc, *Carnegie Mellon University*
-   PhD Student, *University of Pittsburgh*
:::
::: {.fragment .mt1}
#### Research Areas

-   Psychological/Clinical Assessment
-   Affective/Interpersonal Communication
-   Applied Statistics and [Machine Learning]{.b .green}
-   [Data Science]{.b .green} and Software Engineering
:::
:::
:::

## Workshop Overview
1. Conceptual Introductions

2. Walkthrough #1 (Classification)

3. Walkthrough #2 (Regression)

4. Advanced Previews

5. Question and Answer

6. Practice Assignments

## Workshop Datasets

- **Walkthrough #1 (Classification)**

  [Drug Consumption](https://raw.githubusercontent.com/jmgirard/tips2022ml/master/data/drug_consumption.csv) $(n=1876, p_{\text{cocaine_user}}=0.36)$

  *How well can we predict who is a cocaine user based on demographics, personality traits, and legal substance use?*

::: {.fragment .mt1}
- **Walkthrough #2 (Regression)**

  [Cali House](https://raw.githubusercontent.com/jmgirard/tips2022ml/master/data/calihouse_2000.csv) $(n=2000, \text{Min}=\$15\text{k}, \text{Max}=\$500\text{k})$

  *How well can we predict the median house value of a block in 1990 California based on its houses, population, and location?*
:::

<!-- Conceptual Introductions -->

# Conceptual Introductions

## What is machine learning?

- Machine learning (ML) is a **branch of computer science**

- ML researchers **develop algorithms** that [learn from data]{.b .green}

- When algorithms learn from data, they create **models**

::: {.mt1 .fragment}
- This workshop is about creating [predictive models]{.b .green}

- Our goal will be to **use known/available information**...

- To **predict unknown/unavailable information**...

- Ideally in a way that generalized to **novel/unseen data**
:::

::: footer
*Note.* ML researchers also create models for other purposes (e.g., data generation).
:::

## Roles in Predictive Modeling {.f2}

[Labels / Outcomes]{.b .blue}

- Labels are [variables we want to predict]{.b .blue} the unknown values of

- Labels tend to be **expensive** or **difficult to measure** in new data

- Labels may also describe **subjective** experiences or **future** events

- *e.g., diagnoses, treatment response, substance use, suicide attempts*

::: {.mt1 .fragment}
[Features / Predictors]{.b .green}

- Features are [variables we use to predict]{.b .green} the unknown label values

- Features tend to be relatively **cheap** and **easy to measure** in new data

- *e.g., demographics, self-reports, digital behavior, neurobiology*
:::

## Modes of Predictive Modeling {.f2}

[Classification]{.b .blue}

- When labels are [categorical]{.b .blue}, predicting them is called "classification"

- *e.g., Will this patient respond to treatment or not?*

- *e.g., Is this patient depressed, euthymic, or manic?*

::: {.mt1 .fragment}
[Regression]{.b .green}

- When labels are [continuous]{.b .green}, predicting them is called "regression"

- *e.g., How many days will the patient be hospitalized for?*

- *e.g., How much of the drug will be in the patient's blood?*
:::

::: footer
*Note.* Unsupervised ML (or "data mining") has no explicit labels.
:::

## Comprehension Check

::: {.f2}
Ann has developed an ML system that looks at a patient's physiological signals and tries to determine whether they are having a micro-seizure.
:::

::: columns
::: column
::: {.f30}
**1. The features are the _____<br />and the labels are the _____.**

a) physiological signals;<br />physiological signals

b) physiological signals;<br />micro-seizure (yes/no)

c) micro-seizure (yes/no);<br />physiological signals

d) micro-seizure (yes/no);<br />micro-seizure (yes/no)
:::
:::

::: column
::: {.f30}
**2. Which "mode" of predictive modeling is Ann using for her ML system?**

a) Regression<br /><br />

b) Classification<br /><br />

c) Unsupervised Learning<br /><br />

d) Data Mining
:::
:::
:::

## Machine Learning Steps {.f2}

- **Data Preparation**: Importing, Tidying, Splitting
  
::: {.fragment}
- **Model Development**: Feature Engineering, Model Specification
:::

::: {.fragment}
- **Model Tuning**: Resampling, Optimization, Selection
:::

::: {.fragment}
- **Model Evaluation**: Performance, (Comparison), (Utility)
:::

::: {.fragment}
- **Model Use**: Explanation, (Deployment), (Updating)
:::

## Signal and Noise

## Under and Overfitting

## Bias and Variance

## Use cases for ML

<!-- Classification Example -->

# Classification Example
Predict cocaine use from demographics and personality

## 1. Import and tidy data

We load our data from a local text (i.e., CSV) file

We coerce all categorical variables to explicit factors

We retain only features/predictors and our label/outcome

```{r, eval=FALSE, echo=TRUE}
# Load the tidyverse package for data reading and tidying
library(tidyverse)

drugs <- 
  # Read in data from CSV file
  read_csv("./data/drug_consumption.csv", show_col_types = FALSE) |> 
  # Transform categorical variables into factors
  mutate(
    across(c(Age:Ethnicity, Caff:Nicotine), factor),
    Coke = factor(Coke, levels = c(1, 0))  # Set positive class first
  ) |> 
  # Drop unneeded variables
  select(Age:Nicotine, Coke)
```

::: footer
*Note.* Read ["R for Data Science"](https://r4ds.had.co.nz/) to learn about efficient data tidying in R.
:::

## 2. Split data for training and testing

We use 80% of the data for "training" and 20% for "testing"

We stratify both sets by our outcome variable (cocaine use)

```{r, eval=FALSE, echo=TRUE}
# Load the tidymodels package for machine learning
library(tidymodels)

# Set random number generation seed for reproducibility
set.seed(2022)

# Create initial split for holdout validation
coke_split <- initial_split(drugs, prop = 0.8, strata = Coke)

# Extract and save the training set (for development and tuning)
coke_train <- training(coke_split)

# Extract and save the testing set (for evaluation only)
coke_test <- testing(coke_split)
```

::: footer
*Note.* Stratification ensures a similar distribution across all splits.
:::

## 3. Prepare feature engineering recipe

We assign a role ("outcome" or "predictor") to each variable

We engineer (e.g., transform and filter) the features/predictors

```{r, eval=FALSE, echo=TRUE}
coke_recipe <-
  # Initialize the recipe from the training set
  recipe(coke_train) |> 
  # Assign the outcome role to the label variable
  update_role(Coke, new_role = "outcome") |> 
  # Assign the predictor role to the feature variables
  update_role(Age:Nicotine, new_role = "predictor") |> 
  # Dummy code all nominal (i.e., factor) predictors
  step_dummy(all_nominal_predictors()) |> 
  # Remove predictors with near zero variance
  step_nzv(all_predictors()) |> 
  # Remove predictors that are highly inter-correlated
  step_corr(all_predictors()) |> 
  # Remove predictors that are linear combinations
  step_lincomb(all_predictors())
```

::: footer
*Note.* Many other feature engineering steps are available from [{recipes}](https://recipes.tidymodels.org/).
:::

## 4. Set up model and parameters

We specify a Random Forest classifier using {ranger}

We specify that all three model parameters should be tuned

We set the "importance" metric for later model explanations

```{r, eval=FALSE, echo=TRUE}
# Optional: view documentation for the random forest algorithm
?rand_forest

coke_model <-
  # Select the algorithm and which parameters to tune
  rand_forest(mtry = tune(), trees = tune(), min_n = tune()) |> 
  # Select the prediction mode (classification or regression)
  set_mode("classification") |> 
  # Select the engine to use and, optionally, the importance metric
  set_engine("ranger", importance = "impurity")
```

::: footer
*Note.* Many other algorithms and engines are available from [{parsnip}](https://parsnip.tidymodels.org/).
:::

## 5. Prepare workflow

We combine our recipe and model into a "workflow" object

This helps R to repeat everything correctly during tuning

```{r, eval=FALSE, echo=TRUE}
# Combine recipe and model specification into a workflow
coke_wflow <-
  workflow() |> 
  add_recipe(coke_recipe) |> 
  add_model(coke_model)
```

::: footer
*Note.* We could also combine multiple workflows into [{workflowsets}](https://workflowsets.tidymodels.org).
:::

## 6. Tune parameter values

We split the training set into folds for cross-validation

We try lots of different values and record their performance

```{r, eval=FALSE, echo=TRUE}
# Create 10-fold CV within training set for tuning
coke_folds <- vfold_cv(coke_train, v = 10, strata = Coke)

# Pick reasonable boundaries for the tuning parameters
coke_param <-
  extract_parameter_set_dials(coke_model) |> 
  finalize(coke_folds)

# Create and search over a grid of parameter values within boundaries
coke_tune <-
  coke_wflow |> 
  tune_grid(
    resamples = coke_folds,
    param_info = coke_param,
    grid = 20 # how many combinations to try? (more is better but slower)
  )
```

::: footer
*Note.* Other tuning procedures are available from [{tune}](https://tune.tidymodels.org) and  [{finetune}](https://finetune.tidymodels.org).
:::

## 7. Finalize the workflow

We select our final parameter values from the tuning results

We refit to the entire training set and apply it to the testing set

```{r, eval=FALSE, echo=TRUE}
# Select the best parameters values
coke_param_final <- select_best(coke_tune, metric = "accuracy")

# Finalize the workflow with the best parameter values
coke_wflow_final <-
  coke_wflow |> 
  finalize_workflow(coke_param_final)

# Fit the finalized workflow to training set and apply it to testing set
coke_final <-
  coke_wflow_final |> 
  last_fit(coke_split)
```

::: footer
*Note.* More complicated selection procedures are available from [{tune}](https://tune.tidymodels.org).
:::

## 8. Evaluate model performance

We compare the test set predictions to their labels

We make a confusion matrix and ROC curve (for classification)

```{r, eval=FALSE, echo=TRUE}
# View the metrics (from the testing set)
collect_metrics(coke_final)

# Collect predictions (from the testing set)
coke_pred <- collect_predictions(coke_final)
coke_pred

# Calculate and plot confusion matrix
coke_cm <- conf_mat(coke_pred, truth = Coke, estimate = .pred_class)
coke_cm
autoplot(coke_cm, type = "heatmap")
summary(coke_cm)

# Calculate and plot ROC curve
coke_rc <- roc_curve(coke_pred, truth = Coke, .pred_1)
autoplot(coke_rc)
```

::: footer
*Note.* Many other performance tools are available from [{yardstick}](https://yardstick.tidymodels.org).
:::

## Bonus: Explore variable importance

Which variables were most important to prediction?

- Not all algorithms support variable importance measures

```{r, eval=FALSE, echo=TRUE}
# Extract the variable importance measures
coke_final |> 
  extract_fit_parsnip() |> 
  vi()

# Plot the variable importance measures
coke_final |> 
  extract_fit_parsnip() |> 
  vip()
```

::: footer
*Note.* Learn more advanced explainable AI techniques [here](https://ema.drwhy.ai/) or [here](https://christophm.github.io/interpretable-ml-book/).
:::

## Putting it all together

```{r, eval=FALSE, echo=TRUE}
library(tidyverse)
library(tidymodels)
library(vip)

# 1. Import and tidy data
drugs <- 
  read_csv("./data/drug_consumption.csv", show_col_types = FALSE) |> 
  mutate(
    across(c(Age:Ethnicity, Caff:Nicotine), factor),
    Coke = factor(Coke, levels = c(1, 0))
  ) |> 
  select(Age:Nicotine, Coke)

# 2. Split data for training and testing
set.seed(2022)
coke_split <- initial_split(drugs, prop = 0.8, strata = Coke)
coke_train <- training(coke_split)
coke_test <- testing(coke_split)

# 3. Prepare preprocessing recipe
coke_recipe <-
  recipe(coke_train) |> 
  update_role(Coke, new_role = "outcome") |> 
  update_role(Age:Nicotine, new_role = "predictor") |> 
  step_dummy(all_nominal_predictors()) |> 
  step_nzv(all_predictors()) |> 
  step_corr(all_predictors()) |> 
  step_lincomb(all_predictors())

# 4. Set up model and parameters
coke_model <-
  rand_forest(mtry = tune(), trees = tune(), min_n = tune()) |> 
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")

# 5. Prepare workflow
coke_wflow <-
  workflow() |> 
  add_recipe(coke_recipe) |> 
  add_model(coke_model)

# 6. Tune parameters using grid search
coke_folds <- vfold_cv(coke_train, v = 10, strata = Coke)
coke_param <-
  extract_parameter_set_dials(coke_model) |> 
  finalize(coke_folds)
coke_tune <-
  coke_wflow |> 
  tune_grid(
    resamples = coke_folds,
    param_info = coke_param,
    grid = 20
  )

# 7. Finalize the workflow
coke_param_final <- select_best(coke_tune, metric = "accuracy")
coke_wflow_final <-
  coke_wflow |> 
  finalize_workflow(coke_param_final)
coke_final <-
  coke_wflow_final |> 
  last_fit(coke_split)

# 8. Evaluate model performance
collect_metrics(coke_final)
coke_pred <- collect_predictions(coke_final)
coke_cm <- conf_mat(coke_pred, truth = Coke, estimate = .pred_class)
autoplot(coke_cm, type = "heatmap")
summary(coke_cm)
coke_rc <- roc_curve(coke_pred, truth = Coke, .pred_0)
autoplot(coke_rc)

# Bonus: Explore variable importance
coke_final |> 
  extract_fit_parsnip() |> 
  vi()
coke_final |> 
  extract_fit_parsnip() |> 
  vip()
```

<!-- Regression Example -->

# Regression Example

Predict median housing value from block information

## Necessary Changes

To adapt this process to regression, we only need to:

- Assign a continuous variable to the "outcome" role

- Select an algorithm that supports regression

  (Note that some support both, e.g., random forest)
  
- Set the prediction mode to "regression"

- Use regression performance metrics (e.g., RMSE or $R^2$)

- Skip the confusion matrix and ROC curve

  (We can instead plot predictions against trusted labels)

## Putting it all together... again

```{r, eval=FALSE, echo=TRUE}
library(tidyverse)
library(tidymodels)
library(vip)

# 1. Import and tidy data
calihouse <- read_csv("./data/calihouse_2000.csv", show_col_types = FALSE)

# 2. Split data for training and testing
set.seed(2022)
ch_split <- initial_split(calihouse, prop = 0.8, strata = house_mdn_value)
ch_train <- training(ch_split)
ch_test <- testing(ch_split)

# 3. Prepare preprocessing recipe
ch_recipe <-
  recipe(ch_train) |> 
  update_role(house_mdn_value, new_role = "outcome") |>
  update_role(house_mdn_age:dist_sj, new_role = "predictor") |> 
  step_nzv(all_predictors()) |> 
  step_corr(all_predictors()) |> 
  step_lincomb(all_predictors()) |> 
  step_normalize(all_numeric_predictors())

# 4. Set up model and parameters
ch_model <-
  rand_forest(mtry = tune(), trees = tune(), min_n = tune()) |> 
  set_mode("regression") |>
  set_engine("ranger", importance = "impurity")

# 5. Prepare workflow
ch_wflow <-
  workflow() |> 
  add_recipe(ch_recipe) |> 
  add_model(ch_model)

# 6. Tune parameters using grid search
ch_folds <- vfold_cv(ch_train, v = 10, strata = house_mdn_value)
ch_param <-
  ch_model |> 
  extract_parameter_set_dials() |> 
  finalize(ch_folds)
ch_tune <-
  ch_wflow |> 
  tune_grid(
    resamples = ch_folds,
    param_info = ch_param,
    grid = 20
  )

# 7. Finalize the workflow
ch_param_final <- select_best(ch_tune, metric = "rmse")
ch_wflow_final <-
  ch_wflow |> 
  finalize_workflow(ch_param_final)
ch_final <-
  ch_wflow_final |> 
  last_fit(ch_split)

# 8. Evaluate model performance
collect_metrics(ch_final)
ch_pred <- collect_predictions(ch_final)
ggplot(ch_pred, aes(x = house_mdn_value, y = .pred)) +
  geom_point(alpha = 1/5) +
  geom_abline() +
  coord_obs_pred()

# Bonus: Explore variable importance
ch_final |> 
  extract_fit_parsnip() |> 
  vi()
ch_final |> 
  extract_fit_parsnip() |> 
  vip()
```

<!-- Advanced Previews -->

# Advanced Previews

## Data Splitting and Preprocessing {.f30}

- Clustered and longitudinal data
  
  - `rsample::group_vfold_cv()`
  - `rsample::rolling_origin()`

::: {.fragment}
- Nested cross-validation

  - `rsample::nested_cv()`
:::

::: {.fragment}
- Dimensionality Reduction

  - `recipes::step_pca()`
  - `recipes::step_nnmf()`
:::

::: {.fragment}
- Imputing missing predictors

  - `recipes::step_impute_linear()`
  - `recipes::step_impute_knn()`
:::

## Development and Tuning {.f30}

- Alternative algorithms

  - `parsnip::linear_reg(penalty, mixture)`
  - `parsnip::logistic_reg(penalty, mixture)`
  - `parsnip::svm_rbf(cost)`

::: {.fragment}
- Alternative tuning procedures

  - `tune::tune_bayes()`
  - `finetune::tune_sim_anneal()`
  - `finetune::tune_race_anova()`
:::

::: {.fragment}
- Combining models into ensembles

  - `stacks::stacks()`
  - `stacks::blend_predictions()`
:::

## Model Evaluation {.f30}

- Workflow sets and parallelization

  - `workflowsets::workflow_set()`
  - `workflowsets::workflow_map()`
  - `tune::control_grid()`

::: {.fragment}
- Advanced/alternative metrics

  - `yardstick::mcc()` or `yardstick::mn_log_loss()`
  - `yardstick::ccc()` or `yardstick::huber_loss()`
:::

::: {.fragment}
- Statistical model comparison

  - `tidyposterior::perf_mod()`
  - `tidyposterior::contrast_models()`
:::

::: footer
*Note.* The {yardstick} team is currently adding calibration metrics.
:::

## Explanation and Deployment {.f30}

- Advanced model explanations

  - `DALEXtra::explain_tidymodels()`
  - `DALEXtra::model_parts()`
  - `DALEXtra::predict_parts()`
  - `DALEXtra::model_profile()`

::: {.fragment}
- Bundling and deploying models

  - `bundle::bundle()`
  - `vetiver::vetiver_model()`
:::


<!-- Question and Answer -->

# Question and Answer

## Resources {.smaller}

- **Online Textbook:**

  Tidy Modeling with R (Kuhn & Silge)
  
  <https://www.tmwr.org>

::: {.mt1}
- **Package Reference Website:**

  The tidymodels framework (RStudio/Posit)
  
  <https://www.tidymodels.org>
:::

::: {.mt1}
- **Four-day summer course:**

  Applied Machine Learning in R (Girard & Wang)

  <https://www.pittmethods.com/applied-ml>
:::

<!-- Practice Assignments -->

# Practice Assignments

## Practice Assignments {.f2}

1. Refit the model from Walkthrough #1 using regularized logistic regression classification and the GLMNET engine:

```{r, eval=FALSE, echo=TRUE}
logistic_reg(penalty = "tune", mixture = "tune") |> 
set_mode("classification") |> 
set_engine("glmnet")
```

::: {.mt2}
2. Adjust the model from Walkthrough #1 to predict Methamphetamine use (`Meth`) rather than Cocaine use (`Coke`)
:::

::: {.mt2}
3. Adjust the model from Walkthrough #2 to search over a larger grid of 125 parameter values (i.e., 5 unique values for each parameter or $5^3$)
:::

::: {.mt2}
4. Rerun the model from Walkthrough #2 using the [full Cali House dataset](https://github.com/jmgirard/tips2022ml/blob/master/data/calihouse.csv?raw=true) $(n=19675)$ rather than the downsampled version
:::


